{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#===========================================================\n",
    "# prediction flags\n",
    "#===========================================================\n",
    "\n",
    "ID = 'image_id'\n",
    "target_cols = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\n",
    "ROOT = '../input/bengaliai-cv19/'\n",
    "n_grapheme = 168\n",
    "n_vowel = 11\n",
    "n_consonant = 7\n",
    "n_origin = 1295\n",
    "n_total = n_grapheme + n_vowel + n_consonant + n_origin\n",
    "N_JOBS = 4\n",
    "VALIDATION = True\n",
    "FOLD_NUMS = [0, \n",
    "             1, \n",
    "             2,\n",
    "             3, \n",
    "             4\n",
    "            ]\n",
    "RESNET50_FOLDS = ['fold0_best_score.pth', # CV0.9846\n",
    "                  'fold1_best_score.pth', # CV0.9860\n",
    "                  'fold2_best_score.pth', # CV0.9853\n",
    "                  'fold3_best_score.pth', # CV0.9870\n",
    "                  'fold4_best_score.pth', # CV0.9873\n",
    "                 ]\n",
    "EFFICIENTNET_B2_FOLDS = ['fold0_best_score.pth', # CV0.9842\n",
    "                         'fold1_best_score.pth', # CV0.9866\n",
    "                         'fold2_best_score.pth', # CV0.9839\n",
    "                         'fold3_best_score.pth', # CV0.9862\n",
    "                         'fold4_best_score.pth', # CV0.9863\n",
    "                        ]\n",
    "NUM_TTA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================\n",
    "# imports\n",
    "#===========================================================\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/pytorch-pretrained-models/repository/pretrained-models.pytorch-master')\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pretrainedmodels\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, IAAAdditiveGaussianNoise, Normalize, OneOf,\n",
    "    RandomBrightness, RandomContrast, Resize, VerticalFlip, Rotate, ShiftScaleRotate,\n",
    "    RandomBrightnessContrast, OpticalDistortion, GridDistortion, ElasticTransform, Cutout\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "    \n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n",
    "    \n",
    "    log_format = '%(asctime)s %(levelname)s %(message)s'\n",
    "    \n",
    "    stream_handler = StreamHandler()\n",
    "    stream_handler.setLevel(DEBUG)\n",
    "    stream_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    file_handler = FileHandler(log_file)\n",
    "    file_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    logger = getLogger('Bengali')\n",
    "    logger.setLevel(DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "LOG_FILE = 'bengali-train.log'\n",
    "LOGGER = init_logger(LOG_FILE)\n",
    "\n",
    "\n",
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 777\n",
    "seed_torch(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Dataset\n",
    "# =================================================================\n",
    "\n",
    "img_cols = list(map(str, list(np.arange(137*236))))\n",
    "IMG_RESIZE = 128\n",
    "\n",
    "\n",
    "class valid_GraphemeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file_path = f'../input/bengali-images/{self.df.image_id.values[idx]}.png'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = Image.fromarray(np.uint8(image)).convert(\"L\")\n",
    "        image = np.asarray(image)\n",
    "        image = cv2.resize(image, (IMG_RESIZE, IMG_RESIZE)).astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            res = self.transform(image=image)\n",
    "            #image = res['image'].astype(np.float32)\n",
    "            image = res['image']\n",
    "        else:\n",
    "            #image = image.astype(np.float32)\n",
    "            image = image\n",
    "        \n",
    "        image /= 255\n",
    "        image = image[np.newaxis, :, :]\n",
    "        image = 1 - image\n",
    "        image = np.repeat(image, 3, 0)  # 1ch to 3ch\n",
    "        \n",
    "        return torch.tensor(image)\n",
    "    \n",
    "\n",
    "class Test_GraphemeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #image = self.df.iloc[idx][1:].values.reshape(137, 236).astype(np.float32)\n",
    "        image = self.df[idx].reshape(137, 236).astype(np.float32)\n",
    "        image = cv2.resize(image, (IMG_RESIZE, IMG_RESIZE)).astype(np.float32)\n",
    "        #image = self.df.iloc[idx][1:].values.reshape(IMG_RESIZE, IMG_RESIZE).astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            res = self.transform(image=image)\n",
    "            #image = res['image'].astype(np.float32)\n",
    "            image = res['image']\n",
    "        else:\n",
    "            #image = image.astype(np.float32)\n",
    "            image = image\n",
    "        \n",
    "        image /= 255\n",
    "        image = image[np.newaxis, :, :]\n",
    "        image = 1 - image\n",
    "        image = np.repeat(image, 3, 0)  # 1ch to 3ch\n",
    "        \n",
    "        return torch.tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# transforms\n",
    "# =================================================================\n",
    "\n",
    "def get_transforms():\n",
    "    if NUM_TTA>=2:\n",
    "        return Compose([\n",
    "                        Rotate(limit=5, p=0.5),\n",
    "                        ])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# ResNet50\n",
    "# =================================================================\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    \n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "    \n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.avgpool1 = GeM()\n",
    "        self.avgpool2 = GeM()\n",
    "        self.avgpool3 = GeM()\n",
    "        #self.dropout1 = nn.Dropout(0.1)\n",
    "        #self.dropout2 = nn.Dropout(0.1)\n",
    "        #self.dropout3 = nn.Dropout(0.1)\n",
    "        #self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        # grapheme_root\n",
    "        self.fc1 = nn.Linear(512 * block.expansion, n_grapheme)\n",
    "        # vowel_diacritic\n",
    "        self.fc2 = nn.Linear(512 * block.expansion, n_vowel)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(512 * block.expansion, n_consonant)\n",
    "        # grapheme\n",
    "        self.fc4 = nn.Linear(512 * block.expansion * 3, n_origin)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        #x = self.avgpool(x)\n",
    "        #x = torch.flatten(x, 1)\n",
    "        #x = self.fc(x)\n",
    "\n",
    "        x1 = self.avgpool1(x)\n",
    "        x2 = self.avgpool2(x)\n",
    "        x3 = self.avgpool3(x)\n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x3 = torch.flatten(x3, 1)\n",
    "        #x1 = self.dropout1(x1)\n",
    "        #x2 = self.dropout2(x2)\n",
    "        #x3 = self.dropout3(x3)\n",
    "\n",
    "        h_conc = torch.cat((x1, x2, x3), 1)\n",
    "        x4 = self.fc4(h_conc)\n",
    "\n",
    "        x1 = self.fc1(x1)\n",
    "        x2 = self.fc2(x2)\n",
    "        x3 = self.fc3(x3)\n",
    "\n",
    "        return x1, x2, x3, x4\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# efficientnet-b2\n",
    "# https://github.com/lukemelas/EfficientNet-PyTorch/tree/master/efficientnet_pytorch\n",
    "# =================================================================\n",
    "import re\n",
    "import math\n",
    "import collections\n",
    "from functools import partial\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "########################################################################\n",
    "############### HELPERS FUNCTIONS FOR MODEL ARCHITECTURE ###############\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# Parameters for the entire model (stem, all blocks, and head)\n",
    "GlobalParams = collections.namedtuple('GlobalParams', [\n",
    "    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate',\n",
    "    'num_classes', 'width_coefficient', 'depth_coefficient',\n",
    "    'depth_divisor', 'min_depth', 'drop_connect_rate', 'image_size'])\n",
    "\n",
    "# Parameters for an individual model block\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n",
    "\n",
    "# Change namedtuple defaults\n",
    "GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "\n",
    "class SwishImplementation(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class MemoryEfficientSwish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return SwishImplementation.apply(x)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def round_filters(filters, global_params):\n",
    "    \"\"\" Calculate and round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.width_coefficient\n",
    "    if not multiplier:\n",
    "        return filters\n",
    "    divisor = global_params.depth_divisor\n",
    "    min_depth = global_params.min_depth\n",
    "    filters *= multiplier\n",
    "    min_depth = min_depth or divisor\n",
    "    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n",
    "    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%\n",
    "        new_filters += divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, global_params):\n",
    "    \"\"\" Round number of filters based on depth multiplier. \"\"\"\n",
    "    multiplier = global_params.depth_coefficient\n",
    "    if not multiplier:\n",
    "        return repeats\n",
    "    return int(math.ceil(multiplier * repeats))\n",
    "\n",
    "\n",
    "def drop_connect(inputs, p, training):\n",
    "    \"\"\" Drop connect. \"\"\"\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - p\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)\n",
    "    binary_tensor = torch.floor(random_tensor)\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_same_padding_conv2d(image_size=None):\n",
    "    \"\"\" Chooses static padding if you have specified an image size, and dynamic padding otherwise.\n",
    "        Static padding is necessary for ONNX exporting of models. \"\"\"\n",
    "    if image_size is None:\n",
    "        return Conv2dDynamicSamePadding\n",
    "    else:\n",
    "        return partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "\n",
    "\n",
    "class Conv2dDynamicSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a dynamic image size \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        ih, iw = x.size()[-2:]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2])\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class Conv2dStaticSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, image_size=None, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n",
    "\n",
    "        # Calculate padding based on image size and save it\n",
    "        assert image_size is not None\n",
    "        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n",
    "        else:\n",
    "            self.static_padding = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.static_padding(x)\n",
    "        x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "\n",
    "########################################################################\n",
    "############## HELPERS FUNCTIONS FOR LOADING MODEL PARAMS ##############\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def efficientnet_params(model_name):\n",
    "    \"\"\" Map EfficientNet model name to parameter coefficients. \"\"\"\n",
    "    params_dict = {\n",
    "        # Coefficients:   width,depth,res,dropout\n",
    "        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
    "        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
    "        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
    "        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
    "        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
    "        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
    "        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
    "        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
    "        'efficientnet-b8': (2.2, 3.6, 672, 0.5),\n",
    "        'efficientnet-l2': (4.3, 5.3, 800, 0.5),\n",
    "    }\n",
    "    return params_dict[model_name]\n",
    "\n",
    "\n",
    "class BlockDecoder(object):\n",
    "    \"\"\" Block Decoder for readability, straight from the official TensorFlow repository \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _decode_block_string(block_string):\n",
    "        \"\"\" Gets a block through a string notation of arguments. \"\"\"\n",
    "        assert isinstance(block_string, str)\n",
    "\n",
    "        ops = block_string.split('_')\n",
    "        options = {}\n",
    "        for op in ops:\n",
    "            splits = re.split(r'(\\d.*)', op)\n",
    "            if len(splits) >= 2:\n",
    "                key, value = splits[:2]\n",
    "                options[key] = value\n",
    "\n",
    "        # Check stride\n",
    "        assert (('s' in options and len(options['s']) == 1) or\n",
    "                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n",
    "\n",
    "        return BlockArgs(\n",
    "            kernel_size=int(options['k']),\n",
    "            num_repeat=int(options['r']),\n",
    "            input_filters=int(options['i']),\n",
    "            output_filters=int(options['o']),\n",
    "            expand_ratio=int(options['e']),\n",
    "            id_skip=('noskip' not in block_string),\n",
    "            se_ratio=float(options['se']) if 'se' in options else None,\n",
    "            stride=[int(options['s'][0])])\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode_block_string(block):\n",
    "        \"\"\"Encodes a block to a string.\"\"\"\n",
    "        args = [\n",
    "            'r%d' % block.num_repeat,\n",
    "            'k%d' % block.kernel_size,\n",
    "            's%d%d' % (block.strides[0], block.strides[1]),\n",
    "            'e%s' % block.expand_ratio,\n",
    "            'i%d' % block.input_filters,\n",
    "            'o%d' % block.output_filters\n",
    "        ]\n",
    "        if 0 < block.se_ratio <= 1:\n",
    "            args.append('se%s' % block.se_ratio)\n",
    "        if block.id_skip is False:\n",
    "            args.append('noskip')\n",
    "        return '_'.join(args)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(string_list):\n",
    "        \"\"\"\n",
    "        Decodes a list of string notations to specify blocks inside the network.\n",
    "        :param string_list: a list of strings, each string is a notation of block\n",
    "        :return: a list of BlockArgs namedtuples of block args\n",
    "        \"\"\"\n",
    "        assert isinstance(string_list, list)\n",
    "        blocks_args = []\n",
    "        for block_string in string_list:\n",
    "            blocks_args.append(BlockDecoder._decode_block_string(block_string))\n",
    "        return blocks_args\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(blocks_args):\n",
    "        \"\"\"\n",
    "        Encodes a list of BlockArgs to a list of strings.\n",
    "        :param blocks_args: a list of BlockArgs namedtuples of block args\n",
    "        :return: a list of strings, each string is a notation of block\n",
    "        \"\"\"\n",
    "        block_strings = []\n",
    "        for block in blocks_args:\n",
    "            block_strings.append(BlockDecoder._encode_block_string(block))\n",
    "        return block_strings\n",
    "\n",
    "\n",
    "def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2, image_size=None, num_classes=1000):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n",
    "        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=num_classes,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None,\n",
    "        image_size=image_size,\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "def get_model_params(model_name, override_params):\n",
    "    \"\"\" Get the block args and global params for a given model \"\"\"\n",
    "    if model_name.startswith('efficientnet'):\n",
    "        w, d, s, p = efficientnet_params(model_name)\n",
    "        # note: all models have drop connect rate = 0.2\n",
    "        blocks_args, global_params = efficientnet(\n",
    "            width_coefficient=w, depth_coefficient=d, dropout_rate=p, image_size=s)\n",
    "    else:\n",
    "        raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n",
    "    if override_params:\n",
    "        # ValueError will be raised here if override_params has fields not included in global_params.\n",
    "        global_params = global_params._replace(**override_params)\n",
    "    return blocks_args, global_params\n",
    "\n",
    "\n",
    "def load_pretrained_weights(model, model_name, load_fc=True, advprop=False):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    # AutoAugment or Advprop (different preprocessing)\n",
    "    efficientnet_pretrained_path = '../input/pytorch-pretrained-models/efficientnet-b2-8bb594d6.pth'\n",
    "    state_dict = torch.load(efficientnet_pretrained_path)\n",
    "    if load_fc:\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    else:\n",
    "        state_dict.pop('_fc.weight')\n",
    "        state_dict.pop('_fc.bias')\n",
    "        res = model.load_state_dict(state_dict, strict=False)\n",
    "        assert set(res.missing_keys) == set(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))\n",
    "\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "    Args:\n",
    "        block_args (namedtuple): BlockArgs, see above\n",
    "        global_params (namedtuple): GlobalParam, see above\n",
    "    Attributes:\n",
    "        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_args, global_params):\n",
    "        super().__init__()\n",
    "        self._block_args = block_args\n",
    "        self._bn_mom = 1 - global_params.batch_norm_momentum\n",
    "        self._bn_eps = global_params.batch_norm_epsilon\n",
    "        self.has_se = (self._block_args.se_ratio is not None) and (0 < self._block_args.se_ratio <= 1)\n",
    "        self.id_skip = block_args.id_skip  # skip connection and drop connect\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Expansion phase\n",
    "        inp = self._block_args.input_filters  # number of input channels\n",
    "        oup = self._block_args.input_filters * self._block_args.expand_ratio  # number of output channels\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            self._expand_conv = Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = self._block_args.kernel_size\n",
    "        s = self._block_args.stride\n",
    "        self._depthwise_conv = Conv2d(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1, int(self._block_args.input_filters * self._block_args.se_ratio))\n",
    "            self._se_reduce = Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        final_oup = self._block_args.output_filters\n",
    "        self._project_conv = Conv2d(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        \"\"\"\n",
    "        :param inputs: input tensor\n",
    "        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n",
    "        :return: output of block\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            x = self._swish(self._bn0(self._expand_conv(inputs)))\n",
    "        x = self._swish(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_expand(self._swish(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        input_filters, output_filters = self._block_args.input_filters, self._block_args.output_filters\n",
    "        if self.id_skip and self._block_args.stride == 1 and input_filters == output_filters:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "    def set_swish(self, memory_efficient=True):\n",
    "        \"\"\"Sets swish function as memory efficient (for training) or standard (for export)\"\"\"\n",
    "        self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        #self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self._dropout = nn.Dropout(self._global_params.dropout_rate)\n",
    "        #self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "\n",
    "        self.avgpool1 = GeM()\n",
    "        self.avgpool2 = GeM()\n",
    "        self.avgpool3 = GeM()\n",
    "\n",
    "        # grapheme_root\n",
    "        self.fc1 = nn.Linear(out_channels, n_grapheme)\n",
    "        # vowel_diacritic\n",
    "        self.fc2 = nn.Linear(out_channels, n_vowel)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(out_channels, n_consonant)\n",
    "        # grapheme\n",
    "        self.fc4 = nn.Linear(out_channels * 3, n_origin)\n",
    "\n",
    "    def set_swish(self, memory_efficient=True):\n",
    "        \"\"\"Sets swish function as memory efficient (for training) or standard (for export)\"\"\"\n",
    "        self._swish = MemoryEfficientSwish() if memory_efficient else Swish()\n",
    "        for block in self._blocks:\n",
    "            block.set_swish(memory_efficient)\n",
    "\n",
    "\n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = self._swish(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = self._swish(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "        bs = inputs.size(0)\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        #x = self._avg_pooling(x)\n",
    "        #x = x.view(bs, -1)\n",
    "        x1 = self.avgpool1(x)\n",
    "        x2 = self.avgpool2(x)\n",
    "        x3 = self.avgpool3(x)\n",
    "        x1 = x1.view(bs, -1)\n",
    "        x2 = x2.view(bs, -1)\n",
    "        x3 = x3.view(bs, -1)\n",
    "\n",
    "        h_conc = torch.cat((x1, x2, x3), 1)\n",
    "        x4 = self.fc4(h_conc)\n",
    "\n",
    "        #x = self._dropout(x)\n",
    "        #x = self._fc(x)\n",
    "        x1 = self.fc1(x1)\n",
    "        x2 = self.fc2(x2)\n",
    "        x3 = self.fc3(x3)\n",
    "        return x1, x2, x3, x4\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return cls(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, advprop=False, num_classes=1000, in_channels=3):\n",
    "        model = cls.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000), advprop=advprop)\n",
    "        if in_channels != 3:\n",
    "            Conv2d = get_same_padding_conv2d(image_size = model._global_params.image_size)\n",
    "            out_channels = round_filters(32, model._global_params)\n",
    "            model._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name):\n",
    "        \"\"\" Validates model name. \"\"\"\n",
    "        valid_models = ['efficientnet-b'+str(i) for i in range(9)]\n",
    "        if model_name not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))\n",
    "\n",
    "\n",
    "class Efficientnetb2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.net = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "        self.net = EfficientNet.from_name('efficientnet-b2')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-16 04:39:55,504 INFO [validation] start\n",
      "157it [00:58,  2.67it/s]\n",
      "157it [00:40,  3.89it/s]\n",
      "157it [00:55,  2.82it/s]\n",
      "157it [00:41,  3.75it/s]\n",
      "157it [00:54,  2.86it/s]\n",
      "157it [00:41,  3.79it/s]\n",
      "157it [00:56,  2.80it/s]\n",
      "157it [00:41,  3.81it/s]\n",
      "157it [00:56,  2.78it/s]\n",
      "157it [00:41,  3.76it/s]\n",
      "2020-03-16 04:48:16,482 INFO [validation] done in 501 s.\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# validation\n",
    "# =================================================================\n",
    "\n",
    "if VALIDATION:\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    import sklearn.metrics\n",
    "\n",
    "    folds = pd.read_csv('../input/bengali-resnet50-v3/folds.csv')\n",
    "\n",
    "    predictions_ids = []\n",
    "    resnet_predictions1 = []\n",
    "    resnet_predictions2 = []\n",
    "    resnet_predictions3 = []\n",
    "    efficientnet_predictions1 = []\n",
    "    efficientnet_predictions2 = []\n",
    "    efficientnet_predictions3 = []\n",
    "    batch_size = 256\n",
    "\n",
    "    with timer('validation'):\n",
    "        \n",
    "        for num in FOLD_NUMS:\n",
    "\n",
    "            val_idx = folds[folds['fold'] == num].index\n",
    "            df = folds.loc[val_idx].reset_index(drop=True)\n",
    "            predictions_ids.append(list(df[ID].values))\n",
    "            test_dataset = valid_GraphemeDataset(df, \n",
    "                                                 transform=get_transforms(),\n",
    "                                                 #transform=None,\n",
    "                                                )\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=N_JOBS)\n",
    "            \n",
    "            # ResNet50\n",
    "            FOLD = RESNET50_FOLDS[num]\n",
    "            model = resnet50()\n",
    "            model.load_state_dict(torch.load(f'../input/bengali-resnet50-v3/resnet50_{FOLD}'))\n",
    "            model.to(device)\n",
    "\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            model.eval()\n",
    "            \n",
    "            resnet_preds1 = []\n",
    "            resnet_preds2 = []\n",
    "            resnet_preds3 = []\n",
    "\n",
    "            for i, images in tqdm(enumerate(test_loader)):\n",
    "\n",
    "                images = images.to(device) \n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_preds1, y_preds2, y_preds3, _ = model(images)\n",
    "\n",
    "                resnet_preds1.append(list(y_preds1.to('cpu').numpy()))\n",
    "                resnet_preds2.append(list(y_preds2.to('cpu').numpy()))\n",
    "                resnet_preds3.append(list(y_preds3.to('cpu').numpy()))\n",
    "            \n",
    "            flatten_resnet_preds1 = sum(resnet_preds1, [])\n",
    "            flatten_resnet_preds2 = sum(resnet_preds2, [])\n",
    "            flatten_resnet_preds3 = sum(resnet_preds3, [])\n",
    "\n",
    "            # efficinetnet-b2\n",
    "            FOLD = EFFICIENTNET_B2_FOLDS[num]\n",
    "            model = Efficientnetb2()\n",
    "            model.load_state_dict(torch.load(f'../input/bengali-efficientnetb2/efficientnet-b2_{FOLD}'))\n",
    "            model.to(device)\n",
    "\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            model.eval()\n",
    "            \n",
    "            efficientnet_preds1 = []\n",
    "            efficientnet_preds2 = []\n",
    "            efficientnet_preds3 = []\n",
    "\n",
    "            for i, images in tqdm(enumerate(test_loader)):\n",
    "\n",
    "                images = images.to(device) \n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_preds1, y_preds2, y_preds3, _ = model(images)\n",
    "\n",
    "                efficientnet_preds1.append(list(y_preds1.to('cpu').numpy()))\n",
    "                efficientnet_preds2.append(list(y_preds2.to('cpu').numpy()))\n",
    "                efficientnet_preds3.append(list(y_preds3.to('cpu').numpy()))\n",
    "            \n",
    "            flatten_efficientnet_preds1 = sum(efficientnet_preds1, [])\n",
    "            flatten_efficientnet_preds2 = sum(efficientnet_preds2, [])\n",
    "            flatten_efficientnet_preds3 = sum(efficientnet_preds3, [])\n",
    "            \n",
    "            resnet_predictions1.append(flatten_resnet_preds1)\n",
    "            resnet_predictions2.append(flatten_resnet_preds2)\n",
    "            resnet_predictions3.append(flatten_resnet_preds3)\n",
    "            efficientnet_predictions1.append(flatten_efficientnet_preds1)\n",
    "            efficientnet_predictions2.append(flatten_efficientnet_preds2)\n",
    "            efficientnet_predictions3.append(flatten_efficientnet_preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_resnet_preds1 = sum(resnet_predictions1, [])\n",
    "flatten_resnet_preds2 = sum(resnet_predictions2, [])\n",
    "flatten_resnet_preds3 = sum(resnet_predictions3, [])\n",
    "flatten_efficientnet_preds1 = sum(efficientnet_predictions1, [])\n",
    "flatten_efficientnet_preds2 = sum(efficientnet_predictions2, [])\n",
    "flatten_efficientnet_preds3 = sum(efficientnet_predictions3, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9835870486592777, 0.9925440485790218, 0.9893531351244654]\n",
      "0.9872678202555106\n"
     ]
    }
   ],
   "source": [
    "sum_predictions_ids = sum(predictions_ids, [])\n",
    "\n",
    "val_df = pd.DataFrame()\n",
    "val_df[ID] = sum_predictions_ids\n",
    "val_df['pred_grapheme_root'] = np.array(flatten_resnet_preds1).argmax(1)\n",
    "val_df['pred_vowel_diacritic'] = np.array(flatten_resnet_preds2).argmax(1)\n",
    "val_df['pred_consonant_diacritic'] = np.array(flatten_resnet_preds3).argmax(1)\n",
    "    \n",
    "eval_df = df.merge(val_df, on=ID)\n",
    "eval_df['pred_grapheme_root'] = eval_df['pred_grapheme_root'].astype(int)\n",
    "eval_df['pred_vowel_diacritic'] = eval_df['pred_vowel_diacritic'].astype(int)\n",
    "eval_df['pred_consonant_diacritic'] = eval_df['pred_consonant_diacritic'].astype(int)\n",
    "\n",
    "scores = []\n",
    "scores.append(sklearn.metrics.recall_score(eval_df['grapheme_root'].values, \n",
    "                                           eval_df['pred_grapheme_root'].values, average='macro'))\n",
    "scores.append(sklearn.metrics.recall_score(eval_df['vowel_diacritic'].values, \n",
    "                                           eval_df['pred_vowel_diacritic'].values, average='macro'))\n",
    "scores.append(sklearn.metrics.recall_score(eval_df['consonant_diacritic'].values, \n",
    "                                           eval_df['pred_consonant_diacritic'].values, average='macro'))\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "print(scores)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficientnet-b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9824088557332425, 0.9913218347459218, 0.9885381231648432]\n",
      "0.9861694173443126\n"
     ]
    }
   ],
   "source": [
    "sum_predictions_ids = sum(predictions_ids, [])\n",
    "\n",
    "val_df = pd.DataFrame()\n",
    "val_df[ID] = sum_predictions_ids\n",
    "val_df['pred_grapheme_root'] = np.array(flatten_efficientnet_preds1).argmax(1)\n",
    "val_df['pred_vowel_diacritic'] = np.array(flatten_efficientnet_preds2).argmax(1)\n",
    "val_df['pred_consonant_diacritic'] = np.array(flatten_efficientnet_preds3).argmax(1)\n",
    "    \n",
    "eval_df = df.merge(val_df, on=ID)\n",
    "eval_df['pred_grapheme_root'] = eval_df['pred_grapheme_root'].astype(int)\n",
    "eval_df['pred_vowel_diacritic'] = eval_df['pred_vowel_diacritic'].astype(int)\n",
    "eval_df['pred_consonant_diacritic'] = eval_df['pred_consonant_diacritic'].astype(int)\n",
    "\n",
    "scores = []\n",
    "scores.append(sklearn.metrics.recall_score(eval_df['grapheme_root'].values, \n",
    "                                           eval_df['pred_grapheme_root'].values, average='macro'))\n",
    "scores.append(sklearn.metrics.recall_score(eval_df['vowel_diacritic'].values, \n",
    "                                           eval_df['pred_vowel_diacritic'].values, average='macro'))\n",
    "scores.append(sklearn.metrics.recall_score(eval_df['consonant_diacritic'].values, \n",
    "                                           eval_df['pred_consonant_diacritic'].values, average='macro'))\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "print(scores)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 401/401 [03:44<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resnet': 0.6320000000000003, 'efficientnet': 0.36799999999999966}\n",
      "0.9863010657508401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_score1 = 0\n",
    "best_weight = 0\n",
    "\n",
    "for v in tqdm(np.arange(0.300, 0.701, 0.001)):\n",
    "    \n",
    "    ENSEMBLE_WEIGHTS = {'resnet': v, 'efficientnet': 1-v}\n",
    "\n",
    "    ensemble_proba1 = ENSEMBLE_WEIGHTS['resnet']*np.array(flatten_resnet_preds1)\\\n",
    "                                    + ENSEMBLE_WEIGHTS['efficientnet']*np.array(flatten_efficientnet_preds1)\n",
    "    \n",
    "    sum_predictions_ids = sum(predictions_ids, [])\n",
    "\n",
    "    val_df = pd.DataFrame()\n",
    "    val_df[ID] = sum_predictions_ids\n",
    "    val_df['pred_grapheme_root'] = ensemble_proba1.argmax(1)\n",
    "    \n",
    "    eval_df = df.merge(val_df, on=ID)\n",
    "    eval_df['pred_grapheme_root'] = eval_df['pred_grapheme_root'].astype(int)\n",
    "    \n",
    "    score = sklearn.metrics.recall_score(eval_df['grapheme_root'].values, \n",
    "                                         eval_df['pred_grapheme_root'].values, average='macro')\n",
    "    if score>best_score1:\n",
    "        best_score1 = score\n",
    "        best_weight = ENSEMBLE_WEIGHTS\n",
    "\n",
    "print(best_weight)\n",
    "print(best_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 401/401 [02:32<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resnet': 0.6780000000000004, 'efficientnet': 0.3219999999999996}\n",
      "0.9929003090148213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_score2 = 0\n",
    "best_weight = 0\n",
    "\n",
    "for v in tqdm(np.arange(0.300, 0.701, 0.001)):\n",
    "    \n",
    "    ENSEMBLE_WEIGHTS = {'resnet': v, 'efficientnet': 1-v}\n",
    "\n",
    "    ensemble_proba2 = ENSEMBLE_WEIGHTS['resnet']*np.array(flatten_resnet_preds2)\\\n",
    "                                    + ENSEMBLE_WEIGHTS['efficientnet']*np.array(flatten_efficientnet_preds2)\n",
    "    \n",
    "    sum_predictions_ids = sum(predictions_ids, [])\n",
    "\n",
    "    val_df = pd.DataFrame()\n",
    "    val_df[ID] = sum_predictions_ids\n",
    "    val_df['pred_vowel_diacritic'] = ensemble_proba2.argmax(1)\n",
    "    \n",
    "    eval_df = df.merge(val_df, on=ID)\n",
    "    eval_df['pred_vowel_diacritic'] = eval_df['pred_vowel_diacritic'].astype(int)\n",
    "    \n",
    "    score = sklearn.metrics.recall_score(eval_df['vowel_diacritic'].values, \n",
    "                                         eval_df['pred_vowel_diacritic'].values, average='macro')\n",
    "    if score>best_score2:\n",
    "        best_score2 = score\n",
    "        best_weight = ENSEMBLE_WEIGHTS\n",
    "    \n",
    "print(best_weight)\n",
    "print(best_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 401/401 [02:30<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resnet': 0.47700000000000015, 'efficientnet': 0.5229999999999999}\n",
      "0.9900635700972875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_score3 = 0\n",
    "best_weight = 0\n",
    "\n",
    "for v in tqdm(np.arange(0.300, 0.701, 0.001)):\n",
    "    \n",
    "    ENSEMBLE_WEIGHTS = {'resnet': v, 'efficientnet': 1-v}\n",
    "\n",
    "    ensemble_proba3 = ENSEMBLE_WEIGHTS['resnet']*np.array(flatten_resnet_preds3)\\\n",
    "                                    + ENSEMBLE_WEIGHTS['efficientnet']*np.array(flatten_efficientnet_preds3)\n",
    "    \n",
    "    sum_predictions_ids = sum(predictions_ids, [])\n",
    "\n",
    "    val_df = pd.DataFrame()\n",
    "    val_df[ID] = sum_predictions_ids\n",
    "    val_df['pred_consonant_diacritic'] = ensemble_proba3.argmax(1)\n",
    "    \n",
    "    eval_df = df.merge(val_df, on=ID)\n",
    "    eval_df['pred_consonant_diacritic'] = eval_df['pred_consonant_diacritic'].astype(int)\n",
    "    \n",
    "    score = sklearn.metrics.recall_score(eval_df['consonant_diacritic'].values, \n",
    "                                         eval_df['pred_consonant_diacritic'].values, average='macro')\n",
    "    if score>best_score3:\n",
    "        best_score3 = score\n",
    "        best_weight = ENSEMBLE_WEIGHTS\n",
    "    \n",
    "print(best_weight)\n",
    "print(best_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9863010657508401, 0.9929003090148213, 0.9900635700972875]\n",
      "0.9888915026534473\n"
     ]
    }
   ],
   "source": [
    "scores = [best_score1, best_score2, best_score3]\n",
    "final_score = np.average(scores, weights=[2,1,1])\n",
    "print(scores)\n",
    "print(final_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
